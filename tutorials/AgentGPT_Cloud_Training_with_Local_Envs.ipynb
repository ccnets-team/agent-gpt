{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgentGPT Cloud Training with Local Environment Integration\n",
    "\n",
    "This notebook demonstrates how to integrate local environment simulators with cloud-based training on AWS SageMaker.\n",
    "\n",
    "While the training job runs on AWS SageMaker (the cloud), the environment simulators are launched on local machines using their IP addresses and specific ports. To ensure successful connectivity:\n",
    "\n",
    "- **Network Accessibility:** Ensure that the SageMaker instance can reach the local IP addresses directly by configuring proper port forwarding (using NAT or VPN, for example) so that the endpoints are accessible.\n",
    "- **Endpoint Configuration:** The simulator endpoints, including both the IP address and port, are provided in the hyperparameter configuration so that the cloud training job can interact with them.\n",
    "\n",
    "This setup allows you to leverage cloud training power while using locally hosted environments for data collection and simulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Launch Local Environment Simulators\n",
    "\n",
    "Below, environment simulators are launched on three different local machines using their respective IP addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch environments on the first local machine\n",
    "from src.env_host.launcher import EnvLauncher\n",
    "\n",
    "first_local_machine_env_launchers = []\n",
    "num_envs = 2\n",
    "for i in range(num_envs):\n",
    "    env_launcher = EnvLauncher.launch_on_local_with_ip(\n",
    "        env_simulator='gym', \n",
    "        ip_address='http://9.67.82.216', \n",
    "        host='0.0.0.0', \n",
    "        port=56780 + i\n",
    "    )\n",
    "    first_local_machine_env_launchers.append(env_launcher)\n",
    "\n",
    "print('First machine environments launched:', first_local_machine_env_launchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Launch environments on the second local machine\n",
    "from src.env_host.launcher import EnvLauncher\n",
    "\n",
    "second_local_machine_env_launchers = []\n",
    "num_envs = 2\n",
    "for i in range(num_envs):\n",
    "    env_launcher = EnvLauncher.launch_on_local_with_ip(\n",
    "        env_simulator='gym', \n",
    "        ip_address='http://40.167.14.65', \n",
    "        host='0.0.0.0', \n",
    "        port=56780 + i\n",
    "    )\n",
    "    second_local_machine_env_launchers.append(env_launcher)\n",
    "\n",
    "print('Second machine environments launched:', second_local_machine_env_launchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch environments on the third local machine\n",
    "from src.env_host.launcher import EnvLauncher\n",
    "\n",
    "third_local_machine_env_launchers = []\n",
    "num_envs = 2\n",
    "for i in range(num_envs):\n",
    "    env_launcher = EnvLauncher.launch_on_local_with_ip(\n",
    "        env_simulator='gym', \n",
    "        ip_address='http://209.172.43.69', \n",
    "        host='0.0.0.0', \n",
    "        port=56780 + i\n",
    "    )\n",
    "    third_local_machine_env_launchers.append(env_launcher)\n",
    "\n",
    "print('Third machine environments launched:', third_local_machine_env_launchers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Configure AWS SageMaker Training\n",
    "\n",
    "This cell sets up the SageMaker configuration required to launch the training job on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.aws_config import SageMakerConfig\n",
    "\n",
    "role_arn = \"arn:aws:iam::123456789012:role/SageMakerExecutionRole\"\n",
    "image_uri = \"agent-gpt-trainer.ccnets.org\"\n",
    "output_path = \"s3://agent-gpt-ap-northeast-2\"\n",
    "instance_type = \"ml.g5.4xlarge\"\n",
    "\n",
    "sagemaker_config = SageMakerConfig(\n",
    "    output_path=output_path, \n",
    "    image_uri=image_uri, \n",
    "    region=\"ap-northeast-2\",\n",
    "    role_arn=role_arn, \n",
    "    instance_type=instance_type, \n",
    "    max_run=24 * 3600\n",
    ")\n",
    "\n",
    "print('SageMaker configuration set:', sagemaker_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Set Hyperparameters and Environment Hosts\n",
    "\n",
    "The next cell initializes the RL model parameters and sets up the environment hosts with the local endpoints. These endpoints will be used by the cloud training job to connect to the local simulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.hyperparams import Hyperparameters, EnvHost, Exploration\n",
    "\n",
    "num_hosts = 2\n",
    "hyperparams = Hyperparameters(env_id='Humanoid-v5')\n",
    "hyperparams.batch_size = 128\n",
    "hyperparams.lr_init = 2e-4\n",
    "hyperparams.lr_end = 1e-6\n",
    "hyperparams.max_steps = 20_000_000\n",
    "hyperparams.set_exploration('continuous', Exploration(type='gaussian_noise'))\n",
    "\n",
    "[hyperparams.set_env_host(\"local\" + f\"{i}\", EnvHost(env_endpoint=\"http://9.67.82.216:\" + f\"{56780 + i}\", num_agents=128)) for i in range(num_hosts)]\n",
    "[hyperparams.set_env_host(\"local\" + f\"{i + num_hosts}\", EnvHost(env_endpoint=\"http://40.167.14.65:\" + f\"{56780 + i}\", num_agents=128)) for i in range(num_hosts)]\n",
    "[hyperparams.set_env_host(\"local\" + f\"{i + 2*num_hosts}\", EnvHost(env_endpoint=\"http://209.172.43.69:\" + f\"{56780 + i}\", num_agents=128)) for i in range(num_hosts)]\n",
    "\n",
    "print('Hyperparameters and environment hosts configured:')\n",
    "print(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Launch Cloud Training\n",
    "\n",
    "Finally, this cell launches the training job on AWS SageMaker. The training job will connect to the local environment endpoints specified in the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: agent-gpt-trainer-2025-02-12-07-29-14-875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-12 07:29:17 Starting - Starting the training job\n",
      "2025-02-12 07:29:17 Pending - Training job waiting for capacity......\n",
      "2025-02-12 07:30:00 Pending - Preparing the instances for training...\n",
      "2025-02-12 07:30:39 Downloading - Downloading the training image...............\n",
      "2025-02-12 07:33:05 Training - Training image download completed. Training in progress....2025-02-12 07:33:52,349#011INFO worker.py:1841 -- Started a local Ray instance.\n",
      "[INFO] Loading hyperparameters from /opt/ml/input/config/hyperparameters.json\n",
      "[INFO] Setting 'batch_size' to: 256\n",
      "[INFO] Setting 'buffer_size' to: 1000000\n",
      "[INFO] Setting 'd_model' to: 384\n",
      "[INFO] Setting 'dropout' to: 0.1\n",
      "[INFO] Setting 'env_hosts' to: {'local0': {'host_id': None, 'env_endpoint': 'http://9.67.82.216:56780', 'num_agents': 128}, 'local1': {'host_id': None, 'env_endpoint': 'http://9.67.82.216:56781', 'num_agents': 128}, 'local2': {'host_id': None, 'env_endpoint': 'http://40.167.14.65:56780', 'num_agents': 128}, 'local3': {'host_id': None, 'env_endpoint': 'http://40.167.14.65:56781', 'num_agents': 128}, 'local4': {'host_id': None, 'env_endpoint': 'http://209.172.43.69:56780', 'num_agents': 128}, 'local5': {'host_id': None, 'env_endpoint': 'http://209.172.43.69:56781', 'num_agents': 128}}\n",
      "[INFO] Setting 'env_id' to: Humanoid-v5\n",
      "[INFO] Setting 'exploration' to: {'continuous': {'type': 'gaussian_noise', 'initial_epsilon': None, 'final_epsilon': None, 'initial_sigma': 0.1, 'final_sigma': 0.001, 'mu': None, 'theta': None, 'ou_sigma': None, 'dt': None, 'initial_stddev': None, 'final_stddev': None}}\n",
      "[INFO] Setting 'gamma_init' to: 0.99\n",
      "[INFO] Setting 'gpt_type' to: gpt2\n",
      "[INFO] Setting 'lambda_init' to: 0.95\n",
      "[INFO] Setting 'lr_end' to: 1e-06\n",
      "[INFO] Setting 'lr_init' to: 0.0005\n",
      "[INFO] Setting 'lr_scheduler' to: exponential\n",
      "[INFO] Setting 'max_grad_norm' to: 1.0\n",
      "[INFO] Setting 'max_input_states' to: 16\n",
      "[INFO] Setting 'max_steps' to: 50000000\n",
      "[INFO] Setting 'num_heads' to: 8\n",
      "[INFO] Setting 'num_layers' to: 6\n",
      "[INFO] Setting 'replay_ratio' to: 2.0\n",
      "[INFO] Setting 'resume_training' to: False\n",
      "[INFO] Setting 'tau' to: 0.01\n",
      "[INFO] Setting 'use_cloudwatch' to: True\n",
      "[INFO] Setting 'use_graphics' to: False\n",
      "[INFO] Setting 'use_tensorboard' to: True\n",
      "[INFO] Provided Configuration:\n",
      " {\n",
      "    \"batch_size\": \"256\",\n",
      "    \"buffer_size\": \"1000000\",\n",
      "    \"d_model\": \"384\",\n",
      "    \"dropout\": \"0.1\",\n",
      "    \"env_hosts\": \"{'local0': {'host_id': None, 'env_endpoint': 'http://9.67.82.216:56780', 'num_agents': 128}, 'local1': {'host_id': None, 'env_endpoint': 'http://9.67.82.216:56781', 'num_agents': 128}, 'local2': {'host_id': None, 'env_endpoint': 'http://40.167.14.65:56780', 'num_agents': 128}, 'local3': {'host_id': None, 'env_endpoint': 'http://40.167.14.65:56781', 'num_agents': 128}, 'local4': {'host_id': None, 'env_endpoint': 'http://209.172.43.69:56780', 'num_agents': 128}, 'local5': {'host_id': None, 'env_endpoint': 'http://209.172.43.69:56781', 'num_agents': 128}}\",\n",
      "    \"env_id\": \"Humanoid-v5\",\n",
      "    \"exploration\": \"{'continuous': {'type': 'gaussian_noise', 'initial_epsilon': None, 'final_epsilon': None, 'initial_sigma': 0.1, 'final_sigma': 0.001, 'mu': None, 'theta': None, 'ou_sigma': None, 'dt': None, 'initial_stddev': None, 'final_stddev': None}}\",\n",
      "    \"gamma_init\": \"0.99\",\n",
      "    \"gpt_type\": \"gpt2\",\n",
      "    \"lambda_init\": \"0.95\",\n",
      "    \"lr_end\": \"1e-06\",\n",
      "    \"lr_init\": \"0.0005\",\n",
      "    \"lr_scheduler\": \"exponential\",\n",
      "    \"max_grad_norm\": \"1.0\",\n",
      "    \"max_input_states\": \"16\",\n",
      "    \"max_steps\": \"50000000\",\n",
      "    \"num_heads\": \"8\",\n",
      "    \"num_layers\": \"6\",\n",
      "    \"replay_ratio\": \"2.0\",\n",
      "    \"resume_training\": \"False\",\n",
      "    \"tau\": \"0.01\",\n",
      "    \"use_cloudwatch\": \"True\",\n",
      "    \"use_graphics\": \"False\",\n",
      "    \"use_tensorboard\": \"True\"\n",
      "}\n",
      "[INFO] Model directory set to: /opt/ml/model\n",
      "[INFO] Checkpoint directory set to: /opt/ml/checkpoints\n",
      "[INFO] Output directory set to: /opt/ml/output\n",
      "Is CUDA available? True\n",
      "Current device: 0\n",
      "GPU count: 1\n",
      "Allocated memory: 0\n",
      "Device was None, set device to cuda\n",
      "[INFO] Unused config keys: ['device']\n",
      "{'node:__internal_head__': 1.0, 'accelerator_type:A10G': 1.0, 'CPU': 16.0, 'object_store_memory': 19143923712.0, 'memory': 38287847424.0, 'node:10.2.65.201': 1.0, 'GPU': 1.0}\n",
      "Setting up the agent GPT trainer.\n",
      "Training Parameters:\n",
      "batch_size: 256, replay_ratio: 2.0, max_steps: 50000000, buffer_size: 1000000, \n",
      "Algorithm Parameters:\n",
      "gamma_init: 0.99, lambda_init: 0.95, max_input_states: 16, exploration: {'continuous': Exploration(type='gaussian_noise', initial_epsilon=None, final_epsilon=None, initial_sigma=0.1, final_sigma=0.001, mu=None, theta=None, ou_sigma=None, dt=None, initial_stddev=None, final_stddev=None)}, \n",
      "Network Parameters:\n",
      "gpt_type: gpt2, num_layers: 6, d_model: 384, dropout: 0.1, num_heads: 8, \n",
      "Optimization Parameters:\n",
      "lr_init: 0.0005, lr_end: 1e-06, lr_scheduler: exponential, tau: 0.01, max_grad_norm: 1.0, \n",
      "Environment Humanoid-v5 created with 2 instance(s).\n",
      "Creating environment with env_id: Humanoid-v5, env_key: 064c2ec516264f8c, envs_num: 2\n",
      "Environment 064c2ec516264f8c closed successfully.\n",
      "Environment Humanoid-v5 created.\n",
      "Creating environment with env_id: Humanoid-v5, env_key: f19f319867524daf, envs_num: 1\n",
      "Environment f19f319867524daf closed successfully.\n",
      "Environment Specifications for Humanoid-v5\n",
      "state_size: 348, action_size: 17\n",
      "continuous_action_sizes: [17], discrete_action_sizes: []\n",
      "Deleting path 'intermediate': local/checkpoints/intermediate\n",
      "Deleted local directory local/checkpoints/intermediate\n",
      "Creating the brain and loading any checkpoints.\n",
      "#033[36m(RLBrain pid=242)#033[0m Initialized log_std for Linear(in_features=384, out_features=17, bias=True)\n",
      "#033[36m(RLBrain pid=242)#033[0m Using GaussianNoise for continuous action layer.\n",
      "#033[36m(RLBrain pid=242)#033[0m selectd lr_scheduler:  exponential  tau:  0.01  max_grad_norm:  1.0  lr_init:  0.0005  lr_end:  1e-06\n",
      "model_config: {'model_type': 'gpt2', 'input_names': ['observation', 'attention_mask', 'control_key'], 'output_names': ['action'], 'dynamic_axes': {'observation': {0: 'batch_size', 1: 'seq_len', 2: 'state_size'}, 'attention_mask': {0: 'batch_size', 1: 'seq_len'}, 'control_key': {0: 'batch_size', 1: 'seq_len', 2: 'control_size'}, 'action': {0: 'batch_size', 1: 'action_size'}}, 'max_input_states': 16, 'state_size': 348, 'control_size': 384, 'observation_space': {'type': 'Box', 'low': [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf], 'high': [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf], 'shape': (348,), 'dtype': 'float64'}, 'action_space': {'type': 'Box', 'low': [-0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645, -0.4000000059604645], 'high': [0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645, 0.4000000059604645], 'shape': (17,), 'dtype': 'float32'}, 'key_id': '0cac8788-063a-4bbb-893e-05944b93fbb5'}\n",
      "Setting up the processor.\n",
      "Setting up concurrency trackers.\n",
      "#015Training Progress:   0%|          | 0/50000000 [00:00<?, ?it/s]/usr/local/lib/python3.9/site-packages/transformers/modeling_attn_mask_utils.py:116: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n",
      "/usr/local/lib/python3.9/site-packages/transformers/modeling_attn_mask_utils.py:164: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "#033[36m(EnvWorker pid=243)#033[0m /usr/local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:227: UserWarning: #033[33mWARN: Expects `terminated` signal to be a boolean, actual type: <class 'numpy.ndarray'>#033[0m\n",
      "#033[36m(EnvWorker pid=243)#033[0m   logger.warn(\n",
      "#033[36m(EnvWorker pid=243)#033[0m /usr/local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:231: UserWarning: #033[33mWARN: Expects `truncated` signal to be a boolean, actual type: <class 'numpy.ndarray'>#033[0m\n",
      "#033[36m(EnvWorker pid=243)#033[0m   logger.warn(\n",
      "#033[36m(EnvWorker pid=243)#033[0m /usr/local/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:245: UserWarning: #033[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'numpy.ndarray'>#033[0m\n",
      "#033[36m(EnvWorker pid=243)#033[0m   logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.agent_gpt import AgentGPT\n",
    "\n",
    "# Launch the training job on AWS SageMaker\n",
    "AgentGPT.train_on_cloud(sagemaker_config, hyperparameters=hyperparams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
